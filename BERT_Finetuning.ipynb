{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMPc4aN84jQphk68PJ2wq8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theneuralbeing/bert-finetuning-webinar/blob/master/BERT_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bTU_UPlfRor",
        "colab_type": "text"
      },
      "source": [
        "# BERT Finetuning with Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiEyOBHLfk5d",
        "colab_type": "text"
      },
      "source": [
        "## Understanding the Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZcTLiMrXC_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozgNVDWgYinS",
        "colab_type": "code",
        "outputId": "9f3f57e8-4e0e-4315-8369-f266e5ddd969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_b_zYKHZAMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2_BQ3A2gHJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence = 'hehidden likes to play'\n",
        "# # Step 1: Tokenize\n",
        "# tokens = tokenizer.tokenize(sentence)\n",
        "# # Step 2: Add [CLS] and [SEP]\n",
        "# tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "# # Step 3: Pad tokens\n",
        "# padded_tokens = tokens + ['[PAD]' for _ in range(20 - len(tokens))]\n",
        "# attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
        "# # Step 4: Segment ids\n",
        "# seg_ids = [0 for _ in range(len(padded_tokens))] #Optional!\n",
        "# # Step 5: Get BERT vocabulary index for each token\n",
        "# token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwwjM45ygHs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Convert to pytorch tensors\n",
        "# token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "# attn_mask = torch.tensor(attn_mask).unsqueeze(0)\n",
        "# seg_ids = torch.tensor(seg_ids).unsqueeze(0)\n",
        "\n",
        "# # Feed them to bert\n",
        "# hidden_reps, cls_head = bert_model(token_ids, attention_mask = attn_mask,\\\n",
        "#                                   token_type_ids = seg_ids)\n",
        "# print(hidden_reps.shape)\n",
        "# print(cls_head.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4uMPQ_Km9_E",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Class and Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDF8EGbJSAmT",
        "colab_type": "code",
        "outputId": "0887a543-a37c-4198-bcef-5c4c31b3f1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=e255081eddd05439f4deea40c5e53186cfac02d0001f3061b53c6c81f186398c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GtmTUYSSCHU",
        "colab_type": "code",
        "outputId": "02cad50c-49cb-483e-d43f-0fd3e2b68661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://raw.githubusercontent.com/theneuralbeing/bert-finetuning-webinar/master/data.zip'\n",
        "\n",
        "# Download the file and unzip it (if we haven't already)\n",
        "if not os.path.exists('./data.zip'):\n",
        "    wget.download(url, './data.zip')\n",
        "    !unzip -q data.zip\n",
        "    print('Unzipped Dataset')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Unzipped Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwmzHMnzn6ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsxKO4u-iTOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LoadDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen):\n",
        "\n",
        "        # Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter=',')\n",
        "\n",
        "        # Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Define the Maxlength for padding/truncating\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'review']\n",
        "        label = self.df.loc[index, 'sentiment']\n",
        "\n",
        "        # Tokenize the sentence\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "\n",
        "        # Inserting the CLS and SEP token at the beginning and end of the sentence\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "        \n",
        "        # Padding/truncating the sentences to the maximum length\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "        \n",
        "        # Convert the sequence to ids with BERT Vocabulary\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        \n",
        "        # Converting the list to a pytorch tensor\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "\n",
        "        # Obtaining the attention mask\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqe1Tn_gU-mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating instances of training and validation set\n",
        "train_set = LoadDataset(filename = 'data/train.csv', maxlen = 64)\n",
        "val_set = LoadDataset(filename = 'data/validation.csv', maxlen = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQBez4GyVISF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating intsances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 32, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = 32, num_workers = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy59x1OzMnne",
        "colab_type": "text"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q5zrt4MonMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyKJ_lHWTi_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "\n",
        "        # Instantiating the BERT model object \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        # Defining layers like dropout and linear\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        # Getting contextualized representations from BERT Layer\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        # Obtaining the representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "        # print('CLS shape: ',cls_rep.shape)\n",
        "\n",
        "        # Feeding cls_rep to the classifier layer\n",
        "        logits = self.classifier(cls_rep)\n",
        "        # print('Logits shape: ',logits.shape)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vifcpKtlU8y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SentimentClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEFyqz_MMvjJ",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOZ_RBDOU68m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "criterion = BCEWithLogitsLoss()\n",
        "optimizer = Adam(model.parameters(), lr = 2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrFxN3mLwLMp",
        "colab_type": "code",
        "outputId": "a7b4c88b-8dd6-4f9a-ed08-afefc4d97560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gubu6At42C_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a function for calculating accuracy\n",
        "def logits_accuracy(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    preds = (probs > 0.5).long()\n",
        "    acc = (preds.squeeze() == labels).float().mean()\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPYi4_6_2C2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining an evaluation function for training \n",
        "def evaluate(net, criterion, val_loader, device):\n",
        "  \n",
        "    losses, accuracies = 0, 0\n",
        "    \n",
        "    # Setting model to evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    count = 0\n",
        "    for (seq, attn_masks, labels) in val_loader:\n",
        "        count += 1\n",
        "\n",
        "        # Move inputs and targets to device\n",
        "        seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "        # Get logit predictions\n",
        "        val_logits = net(seq, attn_masks)\n",
        "\n",
        "        # Calculate loss\n",
        "        val_loss = criterion(val_logits.squeeze(-1), labels.float())\n",
        "        losses += val_loss.item()\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        accuracies += logits_accuracy(val_logits, labels)\n",
        "\n",
        "    return losses / count, accuracies / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OvRi_i4BYqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-95E-ZVVNHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, criterion, optimizer, train_loader, val_loader, device, epochs=4, print_every=100):\n",
        "    \n",
        "    # Move model to device\n",
        "    net.to(device)\n",
        "    # Setting model to training mode\n",
        "    net.train()\n",
        "\n",
        "    print('========== ========== STARTING TRAINING ========== ==========')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print('\\n\\n========== EPOCH {} =========='.format(epoch))        \n",
        "        t1 = time()\n",
        "\n",
        "        for i, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()  \n",
        "\n",
        "            # Moving tensors to device\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "            # Obtaining the logits from the model\n",
        "            logits = net(seq,attn_masks)\n",
        "\n",
        "            # Calculating the loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            # Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clipping gradients to tackle exploding gradients\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "\n",
        "            # Optimization step\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % print_every == 0:\n",
        "                print(\"Iteration {} ==== Loss: {}\".format(i+1, loss.item()))\n",
        "\n",
        "        t2 = time()\n",
        "        print('Time Taken for Epoch: {}'.format(t2-t1))\n",
        "        print('\\n========== Validating ==========')\n",
        "        mean_val_loss, mean_val_acc = evaluate(net, criterion, val_loader, device)\n",
        "        print(\"Validation Loss: {}\\nValidation Accuracy: {}\".format(mean_val_loss, mean_val_acc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWAQPhpoVd2L",
        "colab_type": "code",
        "outputId": "1e19d0f4-921c-4950-f9e7-1ef09ad29432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "%%time\n",
        "# starting training\n",
        "train(model, criterion, optimizer, train_loader, val_loader, device, epochs=1, print_every=100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========== ========== STARTING TRAINING ========== ==========\n",
            "\n",
            "\n",
            "========== EPOCH 0 ==========\n",
            "Iteration 100 ==== Loss: 0.050789203494787216\n",
            "Iteration 200 ==== Loss: 0.19313561916351318\n",
            "Iteration 300 ==== Loss: 0.04948469623923302\n",
            "Iteration 400 ==== Loss: 0.004036957398056984\n",
            "Iteration 500 ==== Loss: 0.05896902456879616\n",
            "Iteration 600 ==== Loss: 0.21616777777671814\n",
            "Iteration 700 ==== Loss: 0.03353407233953476\n",
            "Time Taken for Epoch: 332.3311336040497\n",
            "\n",
            "========== Validating ==========\n",
            "Validation Loss: 0.7222584533603991\n",
            "Validation Accuracy: 0.8335597515106201\n",
            "CPU times: user 3min 45s, sys: 2min 10s, total: 5min 56s\n",
            "Wall time: 7min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GO7grF5FkWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving our model\n",
        "import os\n",
        "\n",
        "if not os.path.isdir(save_path):\n",
        "    os.mkdir(save_path)\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "}, 'model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a2mZPKkSYjO",
        "colab_type": "code",
        "outputId": "812b8199-6f0c-4bcb-96be-afa449116725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading the checkpoints for resuming training\n",
        "checkpoint = torch.load('model.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIX3h8DATQwD",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FnY36M9pYjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba8af435-7e6e-4bde-c1a3-f65187987b6d"
      },
      "source": [
        "# predictor\n",
        "inference_file = torch.load('model.pth')\n",
        "predictor = SentimentClassifier()\n",
        "predictor.load_state_dict(inference_file['model_state_dict'])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfWlpu8Tmgqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(sentence, maxlen=64):\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize the sentence\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "    # Inserting the CLS and SEP token at the beginning and end of the sentence\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "    \n",
        "    # Padding/truncating the sentences to the maximum length\n",
        "    if len(tokens) < maxlen:\n",
        "        tokens = tokens + ['[PAD]' for _ in range(maxlen - len(tokens))]\n",
        "    else:\n",
        "        tokens = tokens[:maxlen-1] + ['[SEP]']\n",
        "    \n",
        "    # Convert the sequence to ids with BERT Vocabulary\n",
        "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    \n",
        "    # Converting the list to a pytorch tensor\n",
        "    tokens_ids_tensor = torch.tensor(tokens_ids).unsqueeze(0)\n",
        "\n",
        "    # Obtaining the attention mask\n",
        "    attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "    return tokens_ids_tensor, attn_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCRRcFPfMY1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining an evaluation function for training \n",
        "def predict(net, iseq, masks):\n",
        "    device = 'cpu'\n",
        "    # Setting model to evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    # Move inputs and targets to device\n",
        "    iseq, masks = iseq.to(device), masks.to(device)\n",
        "\n",
        "    # Get logit predictions\n",
        "    p_logit = net(iseq, masks)\n",
        "\n",
        "    probs = torch.sigmoid(p_logit.unsqueeze(-1))\n",
        "    preds = (probs > 0.5).long().squeeze(0)\n",
        "\n",
        "   \n",
        "    return preds, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFuaq52hptQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tokens, test_attn = preprocess('the literally love this movie ever')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KetyiqqJqi9q",
        "colab_type": "code",
        "outputId": "149c77c1-7eff-467a-a479-2d6d7ac575c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred, probability = predict(predictor, test_tokens, test_attn)\n",
        "print(pred, probability)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1]]) tensor([[[0.9984]]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy6dVfPhKz0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}